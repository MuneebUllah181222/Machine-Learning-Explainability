# Machine Learning Explainability
This project was completed as part of my Kaggle course on extracting human-understandable insights from machine learning models. The goal was to demonstrate the use of various techniques for model explainability.

## Tasks completed in this project
- Identified the use cases for model insights
- Implemented permutation importance technique
- Utilized partial plots to understand feature interactions
- Used SHAP (SHapley Additive exPlanations) values to explain model predictions

## Libraries Used
The following libraries were used in this project:

- pandas
- scikit-learn
- eli5
- matplotlib
- pdpbox
- shap
## Dataset Used
The dataset used for this project was the "New York City Taxi Fare Prediction" dataset. This dataset contains information about taxi rides in New York City, including the fare amount, pickup and dropoff locations, and the date and time of the ride.

## Getting Started
## Prerequisites
To run this project, you will need to have Python 3 installed on your system, along with the libraries listed above.

## Installation
You can install the required libraries using pip:
``` Python
pip install pandas scikit-learn eli5 matplotlib pdpbox shap
```
## Usage
To run the project, simply run the machine_learning_explainability.py file using python.

## Conclusion
Machine learning models can often be difficult to interpret, but techniques such as permutation importance, partial plots, and SHAP values can help us to extract meaningful insights from these models. This project demonstrates the use of these techniques on a real-world dataset, and shows how they can be used to gain a better understanding of model predictions.
